{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "%matplotlib inline\n",
    "from pygadgetreader import readsnap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def energies(r, Ep, Ek, stellar_mass):\n",
    "    G = 4.30071e-6\n",
    "    stellar_mass=stellar_mass*1e10\n",
    "    Ep=Ep-G*m*np.size(r)/np.max(r) #correction term \n",
    "    E=Ek+Ep\n",
    "\n",
    "    shift_energy = -np.min(Ep)\n",
    "    E += shift_energy\n",
    "    Ep += shift_energy\n",
    "    \n",
    "    #I chose 300 because this code was initially used for cosmological halos which were way too messed up beyond 300 kpc  \n",
    "    w=np.where((r<300) & (r!=r[0])) \n",
    "    r=r[w]\n",
    "    Ep=Ep[w]\n",
    "    Ek=Ek[w]\n",
    "    E=E[w]\n",
    "    partID=partID[w]\n",
    "    \n",
    "    return r, Ep, Ek, E, partID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binning_data(r, bsize):\n",
    "    \"\"\"\n",
    "    Binning the data in radial bins.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    \n",
    "    Output:\n",
    "    -------\n",
    "    \n",
    "    \"\"\"\n",
    "    MIN,MAX = np.min(np.log10(r)), np.max(np.log10(r))\n",
    "    Nbins = int((MAX-MIN)/bsize)    \n",
    "    histo_rad, redges = np.histogram(np.log10(r), bins = np.linspace(MIN, MAX, Nbins))\n",
    "    rbins = np.ndarray(shape=np.size(redges)-1, dtype=float)   \n",
    "\n",
    "    # centering the bins\n",
    "    dr = (redges[1]-redges[0])/2.\n",
    "    rbins = redges-dr\n",
    "\n",
    "    rbins = 10**rbins    \n",
    "    nn = np.size(rbins)\n",
    "    binsize_r = np.ndarray(shape=nn, dtype=float)   \n",
    "    #     binsize_r is evaluated here for g(E) calculation\n",
    "    for j in range(0,nn-1): \n",
    "        binsize_r[j] = 10**redges[j+1]-10**redges[j]\n",
    "\n",
    "    return rbins, binsize_r, histo_rad, redges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "binning_data(np.linspace(0.001, 300, 100), 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tracers_density(r_s, rbins):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "    ------\n",
    "    r_s : scale radius\n",
    "    rbins : number of radial bins\n",
    "    Returns:\n",
    "    --------\n",
    "    \"\"\"\n",
    "    #nu_tracer=(3.0/(4.0*np.pi*r_s**3))*(1.0+(rbins/r_s)**2)**(-2.5) # PLUMMER\n",
    "    nu_tracer=(stellar_mass*r_s/(2.0*np.pi*rbins))/(r_s+rbins)**3 # HERNQUIST\n",
    "    \n",
    "    return nu_tracer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pot2=np.ndarray(shape=np.size(histo_rad), dtype=float)\n",
    "    for j in range(0, np.size(redges)-1):\n",
    "        wbin=np.where((np.log10(r)>=redges[j]) & (np.log10(r)<redges[j+1]))\n",
    "        if(np.size(wbin)>0):\n",
    "            pot2[j]=np.mean(Ep[wbin]) #reverse indices in IDL is much faster than this junk\n",
    "pot3 = np.ndarray(shape=np.size(histo_rad), dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binning_potential(histo_rad, redges):\n",
    "    pot2=np.ndarray(shape=np.size(histo_rad), dtype=float)\n",
    "    for j in range(0, np.size(redges)-1):\n",
    "        wbin=np.where((np.log10(r)>=redges[j]) & (np.log10(r)<redges[j+1]))\n",
    "        if(np.size(wbin)>0):\n",
    "            pot2[j]=np.mean(Ep[wbin]) #reverse indices in IDL is much faster than this junk\n",
    "    \"\"\"\n",
    "    # forgot why I wanted more than 20 particles in the bins, \n",
    "    # maybe sth to do with gradient not working with missing data\n",
    "    w=np.where(histo_rad>20.)\n",
    "    rbins=rbins[w]\n",
    "    binsize_r=binsize_r[w]\n",
    "    nu_tracer=nu_tracer[w]\n",
    "    pot2=pot2[w]\n",
    "    \"\"\"\"\"\"\n",
    "    pot2-=shift_energy\n",
    "    psi2=(-1.0)*pot2\n",
    "    E-=shift_energy\n",
    "    epsilon=(-1.0)*E \n",
    "    \"\"\"\n",
    "    return pot2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def energy_bins(energy):\n",
    "    Histo_E, Edges = np.histogram(energy, bins=N_Eb)\n",
    "    Ebins=np.ndarray(shape=np.size(Histo_E), dtype=float)\n",
    "    \n",
    "    Ebins=Edges-(Edges[1]-Edges[0])/2.\n",
    "    return Ebins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_triaxial(r, Ek, Ep, a, partID, m, bsize, N_Eb, stellar_mass):\n",
    "    \n",
    "    r, Ep, Ek, stellar_mass = energies(r, Ep, Ek, stellar_mass)\n",
    "    rbins, binsize_r, histo_rad, redges = binning_data(r, bsize)\n",
    "\n",
    "    #TRACER PARAMETRISATION\n",
    "    nu_tracer = tracers_density(r_s, rbins) \n",
    "\n",
    "    pot2 = binning_potential(histo_rad, redges)\n",
    "\n",
    "    #Need to do the reverse indices here - \n",
    "    pot2-=shift_energy\n",
    "    psi2=(-1.0)*pot2\n",
    "    E-=shift_energy\n",
    "    epsilon=(-1.0)*E \n",
    "\n",
    "    #Fetching derivatives from the data necessary for the Eddington formula evalution\n",
    "    dnu_dpsi=np.gradient(psi2, nu_tracer)\n",
    "    dnu2_dpsi2=np.gradient(psi2, dnu_dpsi)\n",
    "    \n",
    "    #Binning Energy for g(E) and f(E) (f(epsilon)) calculations                                \n",
    "    \n",
    "    Ebins = energy_bins(E)\n",
    "    epsilon_bins = energy_bins(epsilon)\n",
    "        \n",
    "    #Total N(E) differential energy distribution\n",
    "    Histo_M=Histo_E*m/np.sqrt((Ebins[2]-Ebins[1])**2) \n",
    "    \n",
    "    \"\"\"\n",
    "    # EDDINGTON FORMULA --------------\n",
    "    dpsi=np.ndarray(shape=np.size(psi2), dtype=float)\n",
    "    for i in range (1, np.size(dpsi)):\n",
    "        dpsi[i]=psi2[i]-psi2[i-1]\n",
    "        \n",
    "    distribution_function=np.ndarray(shape=np.size(epsilon_bins), dtype=float)\n",
    "    \n",
    "    for i in range(0,np.size(epsilon_bins)):\n",
    "        w=np.where(psi2<epsilon_bins[i])\n",
    "        #x=np.min(w) #i don't think I use this anywhere\n",
    "        eps=epsilon_bins[i]\n",
    "        if (np.size(w[0])!=0):\n",
    "            w=np.array(w)\n",
    "            tot1=dpsi[w[0,0]::]\n",
    "            tot2=dnu2_dpsi2[w[0,0]::]\n",
    "            tot3=np.sqrt(2.0*(eps-psi2[w[0,0]::]))\n",
    "            tot=tot1*tot2/tot3\n",
    "            val=(1.0)/(np.sqrt(8.0)*np.pi**2)*np.sum(tot) #Arthur's eval as Sum (in sims no divergence due to res)\n",
    "            #print val, i, \"val, i\"\n",
    "            distribution_function[i]=val\n",
    "        else:\n",
    "            distribution_function[i]=0\n",
    "            \n",
    "    #DENSITY OF STATES--------------\n",
    "    wrme=np.ndarray(shape=np.size(Ebins), dtype=int)\n",
    "    rme=np.ndarray(shape=np.size(Ebins), dtype=float)\n",
    "    for i in range(0, np.size(Ebins)): \n",
    "        wpot_equals_E=np.where(pot2<=Ebins[i]) \n",
    "        if (np.size(wpot_equals_E)!=0):\n",
    "            wrme[i]=np.max(np.array(wpot_equals_E))\n",
    "        else:\n",
    "            wrme[i]=0\n",
    "            \n",
    "    density_of_states=np.ndarray(shape=np.size(Ebins), dtype=float) # density of states integral (evaluated as sum)\n",
    "    for i in range(0,np.size(Ebins)):\n",
    "        if (np.size(wrme[i])==0):\n",
    "            g1=0.0 \n",
    "        else:\n",
    "            g1=rbins[0:wrme[i]]**2\n",
    "            g2=np.sqrt(2.0*(Ebins[i]-pot2[0:wrme[i]]))\n",
    "            density_of_states[i]=(4.0*np.pi)**2*np.sum(binsize_r[0:wrme[i]]*g1*g2)\n",
    "                                                              \n",
    "    indsort=np.argsort(distribution_function) #sorted indices\n",
    "    indsort=indsort[::-1] #reverse   \n",
    "    # weights= D.F(tracers)/ (D.F.(self-consistent)) - self-consistent D.F. f(E) generates the potential Phi \n",
    "    # N(E)=f(E)*g(E)\n",
    "    Weights=distribution_function[indsort[::-1]]/((Histo_M)/density_of_states) \n",
    "\n",
    "    # cast the weights to every particle\n",
    "    Weights_array=np.ndarray(shape=np.size(r), dtype=float) \n",
    "    for j in range(0, np.size(Edges)-1):\n",
    "        wbin=np.where((E>=Edges[j]) & (E<Edges[j+1]))\n",
    "        if(np.size(wbin[0])!=0):\n",
    "            Weights_array[wbin]=Weights[j] \n",
    "    \n",
    "    #Ensure that the sum of the weights = mass of the tracers - this is not strictly needed\n",
    "    X=stellar_mass/(np.sum(Weights_array)*m)\n",
    "    Weights_array=Weights_array*X\n",
    "    print(np.size(Weights_array))\n",
    "\n",
    "    #return the IDS from which the weights are associated to the particles\n",
    "    #needed for tracking where the tracers end up in subsequent snapshots\n",
    "    return {'weights':Weights_array, 'ids':partID} \n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
